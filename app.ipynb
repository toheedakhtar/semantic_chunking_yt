{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting youtube video and its audio  \n",
    "using pytube package of python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pytube\n",
    "! pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --q --upgrade moviepy pytube git+https://github.com/huggingface/transformers.git accelerate datasets[audio]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1 \n",
    "getting audio from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from moviepy.editor import VideoFileClip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting stream value of video from youtube using pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.youtube.com/watch?v=Sby1uJ_NFIY'\n",
    "# url = 'https://www.youtube.com/watch?v=CeSAjK2CBEA&t=81s'\n",
    "\n",
    "yt_vid = YouTube(url) \n",
    "\n",
    "# progressive streams have video and audigo in a single file \n",
    "# but are only for upto 720p\n",
    "yt_vid.streams.filter(progressive=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download video from youtube url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(yt_url):\n",
    "    try:\n",
    "        video = YouTube(yt_url)\n",
    "        video.streams.get_by_itag(22).download(filename='video.mp4')\n",
    "        print('Video succesfully downloaded from Youtube')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to download Youtube video \\nerror : {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting audio from downloaded video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_from_video(video_path):\n",
    "    try:\n",
    "        video = VideoFileClip(video_path)\n",
    "        audio = video.audio\n",
    "        audio.write_audiofile('audio.wav')   \n",
    "        video.close()\n",
    "        audio.close()\n",
    "    except Exception as e:\n",
    "        print(f'Failed to extract audio from video \\nerror : {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video succesfully downloaded from Youtube\n",
      "MoviePy - Writing audio in audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "url = 'https://www.youtube.com/watch?v=CeSAjK2CBEA&t=81s'\n",
    "video_path = './video.mp4'\n",
    "\n",
    "get_video(url)\n",
    "audio_from_video(video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2 \n",
    "Transcription of audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "audio processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = wave.open('./audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of channels :  2\n",
      "sample width :  2\n",
      "frame rate :  44100\n",
      "Number of frames :  7769979\n",
      "parameters _wave_params(nchannels=2, sampwidth=2, framerate=44100, nframes=7769979, comptype='NONE', compname='not compressed')\n"
     ]
    }
   ],
   "source": [
    "print(\"number of channels : \", obj.getnchannels())\n",
    "print(\"sample width : \", obj.getsampwidth())\n",
    "print(\"frame rate : \", obj.getframerate())\n",
    "print(\"Number of frames : \", obj.getnframes())\n",
    "print(\"parameters\", obj.getparams())\n",
    "\n",
    "obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176.19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_audio = obj.getnframes() / obj.getframerate()\n",
    "t_audio # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "read of closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadframes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(frames), \u001b[38;5;28mtype\u001b[39m(frames[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(frames))\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\wave.py:362\u001b[0m, in \u001b[0;36mWave_read.readframes\u001b[1;34m(self, nframes)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nframes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 362\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_chunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnframes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_framesize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampwidth \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mbyteorder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbig\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    364\u001b[0m     data \u001b[38;5;241m=\u001b[39m _byteswap(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampwidth)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\wave.py:178\u001b[0m, in \u001b[0;36m_Chunk.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_read:\n\u001b[0;32m    177\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_read\n\u001b[1;32m--> 178\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_read \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_read \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    181\u001b[0m    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    182\u001b[0m    (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\wave.py:178\u001b[0m, in \u001b[0;36m_Chunk.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_read:\n\u001b[0;32m    177\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_read\n\u001b[1;32m--> 178\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39mread(size)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_read \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_read \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    181\u001b[0m    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    182\u001b[0m    (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: read of closed file"
     ]
    }
   ],
   "source": [
    "frames = obj.readframes(-1)\n",
    "print(type(frames), type(frames[0]))\n",
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting the wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "samp_freq =  obj.getframerate()\n",
    "n_samples = obj.getnframes()\n",
    "signal_wave = obj.readframes(-1)\n",
    "\n",
    "obj.close()\n",
    "\n",
    "t_audio = n_samples / samp_freq\n",
    "type(signal_wave)\n",
    "signal_wave\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing dependencies\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using openai whisper model (tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"openai/whisper-tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline at 0x210d4991a10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=15,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = 'audio.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    }
   ],
   "source": [
    "text_audio = pipeline(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting transcribed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" When you grow up you tend to get told that the world is the way it is and your life is just to live your life inside the world, try not to bash into the walls too much. But life can be much broader once you discover one simple fact, and that is everything around you that you call life was made up by people that were no smarter than you. And you can change it, you can influence it, you can build your own things that other people can use. Good evening. I'm Steve Jobs from Apple Computer, We're very glad to be here tonight. I think you always had to be a little different to buy an Apple computer. And I think you still have to think differently to buy an Apple computer. And I think the people that do buy this. still have to think differently to buy and have a computer. And I think the people that do buy them, they are the people that are not just out to get a job done, they're out to change the world. What a computer is to me is it's the most remarkable tool that we've ever come up with. And it's the equivalent of a bicycle for our minds. This is IMAG, the whole thing is translucent. You can see into it. It's so cool. Please to announce today that I'm gonna drop the interim title. Please to stand at the intersection of technology and humanity. And to make something for people that want to bring this into their lives and use it for things that make them more creative, not just make them more productive. This amazing little device holds a thousand songs because right in my pocket. An iPod, a phone, and an internet communicator. An iPod. A phone. Are you getting it? And we are falling it. iPhone. We have a chance if we stay focused and choose wisely to really continue to impact people's lives in some small way for the better. There's an old Wayne Gratsky quote that I love. I skate to where the puck is going to be, not where it has been. And we've always tried to do that at Apple, since the very, very very begin and we always will. So thank you very very much for being part of this. Thank you. you\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_audio['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_audio['chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=0\n",
    "for i in chunks:\n",
    "    j += 1\n",
    "\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_id = []\n",
    "timestamps = []\n",
    "texts = []\n",
    "start_time = []\n",
    "end_time = []\n",
    "\n",
    "for i in range(0, j):\n",
    "  chunk_id.append(i)\n",
    "  texts.append(chunks[i]['text'])\n",
    "  start_time.append(chunks[i]['timestamp'][0])\n",
    "  end_time.append(chunks[i]['timestamp'][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 14.82, 17.52, 24.64, 31.74, 38.16, 44.0, 48.0, 52.0, 53.44]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.82, 17.52, 24.64, 31.74, 36.0, 44.0, 48.0, 52.0, 53.44, 55.76]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_length = []\n",
    "for i in range(0, j-1):\n",
    "    chunk_length.append(round(end_time[i] - start_time[i], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
